import streamlit as st
import gdown
import zipfile
import os
import sqlite3
import datetime
import gc
import time
import google.generativeai as genai
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import FAISS

# =====================================================
# 1. C·∫§U H√åNH TRANG & CSS (GIAO DI·ªÜN)
# =====================================================
st.set_page_config(
    page_title="Yoga Assistant Pro",
    page_icon="üßò",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# CSS T√πy ch·ªânh: L√†m ƒë·∫πp khung chat, ·∫©n header m·∫∑c ƒë·ªãnh, thi·∫øt k·∫ø th·∫ª qu·∫£ng c√°o
st.markdown("""
<style>
    /* ·∫®n Header m·∫∑c ƒë·ªãnh c·ªßa Streamlit */
    header[data-testid="stHeader"] {visibility: hidden;}
    footer {visibility: hidden;}
    .stDeployButton {display:none;}
    
    /* N·ªÅn tr·∫Øng s·∫°ch s·∫Ω */
    .stApp { background-color: #ffffff; }

    /* Khung Chat Input c·ªë ƒë·ªãnh d∆∞·ªõi c√πng */
    div[data-testid="stChatInput"] {
        position: fixed;
        bottom: 20px;
        left: 50%;
        transform: translateX(-50%);
        width: 90%;
        max-width: 800px;
        z-index: 1000;
        background-color: white;
        border-radius: 30px;
        box-shadow: 0 4px 20px rgba(0,0,0,0.1);
        padding: 5px;
        border: 1px solid #e0e0e0;
    }
    
    /* Thanh Qu·∫£ng C√°o (Banner) */
    .promo-banner {
        background: linear-gradient(90deg, #fff3e0 0%, #ffe0b2 100%);
        border-left: 5px solid #ff9800;
        padding: 12px 20px;
        margin-bottom: 25px;
        border-radius: 8px;
        display: flex;
        align-items: center;
        justify-content: space-between;
        box-shadow: 0 2px 5px rgba(0,0,0,0.05);
    }
    .promo-text { color: #e65100; font-weight: bold; font-size: 15px; }
    .promo-sub { color: #ef6c00; font-size: 13px; }
    .promo-btn {
        background-color: #ff9800; color: white !important;
        padding: 8px 16px; border-radius: 20px;
        text-decoration: none; font-weight: bold; font-size: 13px;
        box-shadow: 0 2px 5px rgba(230, 81, 0, 0.3);
        transition: all 0.3s;
    }
    .promo-btn:hover { background-color: #e65100; transform: translateY(-1px); }

    /* Giao di·ªán tin nh·∫Øn */
    .stChatMessage { padding: 10px; border-radius: 10px; }
    div[data-testid="stMarkdownContainer"] p { font-size: 16px; line-height: 1.6; }
    
    /* H·ªôp ngu·ªìn tham kh·∫£o */
    .source-box {
        background-color: #f1f8e9;
        border: 1px solid #c5e1a5;
        border-radius: 10px;
        padding: 15px;
        margin-top: 15px;
        font-size: 0.9em;
    }
    .source-title { font-weight: bold; color: #33691e; margin-bottom: 8px; display: flex; align-items: center; gap: 5px; }
    .source-link { 
        display: block; margin-bottom: 6px; 
        text-decoration: none; color: #2e7d32; 
        font-weight: 500; transition: 0.2s;
    }
    .source-link:hover { color: #1b5e20; text-decoration: underline; }
    .tag-type { 
        font-size: 0.7em; padding: 2px 6px; border-radius: 4px; 
        margin-right: 8px; font-weight: bold; text-transform: uppercase;
    }
    .tag-science { background: #e3f2fd; color: #1565c0; border: 1px solid #bbdefb; }
    .tag-blog { background: #e8f5e9; color: #2e7d32; border: 1px solid #c8e6c9; }

    /* Thanh gi·ªõi h·∫°n l∆∞·ª£t d√πng */
    .usage-bar-wrapper {
        position: fixed; top: 0; left: 0; width: 100%; height: 4px;
        background: #f0f0f0; z-index: 9999;
    }
    .usage-fill { height: 100%; background: linear-gradient(90deg, #4db6ac, #009688); transition: width 0.5s; }
    .usage-badge {
        position: fixed; top: 10px; right: 10px;
        background: rgba(255,255,255,0.95);
        padding: 4px 12px; border-radius: 15px;
        font-size: 12px; color: #00796b; font-weight: bold;
        border: 1px solid #b2dfdb; z-index: 10000;
        box-shadow: 0 2px 5px rgba(0,0,0,0.1);
    }
</style>
""", unsafe_allow_html=True)

# =====================================================
# 2. KH·ªûI T·∫†O N√ÉO B·ªò (BACKEND)
# =====================================================
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    file_id = st.secrets["DRIVE_FILE_ID"]
    genai.configure(api_key=api_key)
except:
    st.error("‚ùå L·ªói: Ch∆∞a c·∫•u h√¨nh secrets.toml (Thi·∫øu API Key ho·∫∑c File ID)")
    st.stop()

# ƒê∆∞·ªùng d·∫´n file
ZIP_PATH = "/tmp/brain_data.zip"
EXTRACT_PATH = "/tmp/brain_data_extracted"
DB_PATH = "user_usage.db" # Database SQLite an to√†n

@st.cache_resource
def load_brain_engine():
    """T·∫£i v√† kh·ªüi ƒë·ªông n√£o b·ªô AI m·ªôt l·∫ßn duy nh·∫•t"""
    # 1. T·∫£i file n·∫øu ch∆∞a c√≥
    if not os.path.exists(EXTRACT_PATH):
        try:
            url = f'https://drive.google.com/uc?id={file_id}'
            gdown.download(url, ZIP_PATH, quiet=True)
            
            with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:
                zip_ref.extractall(EXTRACT_PATH)
            
            # D·ªçn d·∫πp RAM ngay l·∫≠p t·ª©c
            if os.path.exists(ZIP_PATH): os.remove(ZIP_PATH)
            gc.collect()
        except Exception as e:
            return None, None, f"L·ªói t·∫£i d·ªØ li·ªáu: {str(e)}"

    # 2. T√¨m file FAISS
    vector_path = None
    for root, dirs, files in os.walk(EXTRACT_PATH):
        for file in files:
            if file.endswith(".faiss"):
                vector_path = root
                break
        if vector_path: break
    
    if not vector_path:
        return None, None, "Kh√¥ng t√¨m th·∫•y file vector (.faiss)"

    # 3. Load Model
    try:
        embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004", google_api_key=api_key)
        vector_db = FAISS.load_local(vector_path, embeddings, allow_dangerous_deserialization=True)
        chat_model = genai.GenerativeModel('gemini-flash-latest')
        return vector_db, chat_model, "OK"
    except Exception as e:
        return None, None, f"L·ªói kh·ªüi ƒë·ªông AI: {str(e)}"

db, model, status = load_brain_engine()

if status != "OK":
    st.warning(f"‚ö†Ô∏è ƒêang b·∫£o tr√¨ h·ªá th·ªëng n√£o b·ªô: {status}. Vui l√≤ng th·ª≠ l·∫°i sau 1 ph√∫t.")
    st.stop()

# =====================================================
# 3. QU·∫¢N L√ù USER & DATABASE (CH·ªêNG S·∫¨P)
# =====================================================
def init_db():
    """T·∫°o database SQLite n·∫øu ch∆∞a c√≥"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    # T·∫°o b·∫£ng: user_id | ng√†y | s·ªë l·∫ßn d√πng
    c.execute('''CREATE TABLE IF NOT EXISTS usage 
                 (user_id TEXT, date TEXT, count INTEGER, PRIMARY KEY (user_id, date))''')
    conn.commit()
    conn.close()

def check_usage(user_id):
    """Ki·ªÉm tra s·ªë l∆∞·ª£t ƒë√£ d√πng h√¥m nay"""
    today = str(datetime.date.today())
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("SELECT count FROM usage WHERE user_id=? AND date=?", (user_id, today))
    result = c.fetchone()
    conn.close()
    return result[0] if result else 0

def increment_usage(user_id):
    """TƒÉng s·ªë l∆∞·ª£t d√πng l√™n 1"""
    today = str(datetime.date.today())
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    # Th·ª≠ insert, n·∫øu tr√πng (ƒë√£ c√≥ h√¥m nay) th√¨ update
    c.execute("INSERT OR IGNORE INTO usage (user_id, date, count) VALUES (?, ?, 0)", (user_id, today))
    c.execute("UPDATE usage SET count = count + 1 WHERE user_id=? AND date=?", (user_id, today))
    conn.commit()
    conn.close()

# Kh·ªüi t·∫°o DB khi ch·∫°y app
init_db()

# L·∫•y ID ng∆∞·ªùi d√πng (N·∫øu ch∆∞a ƒëƒÉng nh·∫≠p th√¨ d√πng IP gi·∫£ l·∫≠p)
def get_user_key():
    if st.session_state.get("authenticated"):
        return st.session_state.username
    # L·∫•y IP ƒë·ªÉ gi·ªõi h·∫°n kh√°ch v√£ng lai
    try:
        from streamlit.web.server.websocket_headers import _get_headers
        headers = _get_headers()
        return headers.get("X-Forwarded-For", "guest_unknown").split(",")[0]
    except:
        return "guest_unknown"

# =====================================================
# 4. LOGIC CH√çNH (SESSION & AUTH)
# =====================================================
if "authenticated" not in st.session_state: st.session_state.authenticated = False
if "messages" not in st.session_state: 
    st.session_state.messages = [{"role":"assistant", "content":"Namaste! üôè T√¥i l√† AI Yoga. B·∫°n ƒëang g·∫∑p v·∫•n ƒë·ªÅ g√¨ (ƒëau l∆∞ng, m·∫•t ng·ªß, hay c·∫ßn l·ªô tr√¨nh t·∫≠p)?"}]

user_id = get_user_key()
used_count = check_usage(user_id)

# C·∫•u h√¨nh gi·ªõi h·∫°n
LIMIT = 30 if st.session_state.authenticated else 5
can_chat = used_count < LIMIT

# Hi·ªÉn th·ªã thanh ti·∫øn tr√¨nh s·ª≠ d·ª•ng
percent = min(100, int((used_count / LIMIT) * 100))
st.markdown(f"""
    <div class="usage-bar-wrapper"><div class="usage-fill" style="width: {percent}%;"></div></div>
    <div class="usage-badge">‚ö° {used_count}/{LIMIT} l∆∞·ª£t</div>
""", unsafe_allow_html=True)

# =====================================================
# D. X·ª¨ L√ù CHAT LOGIC (Strict Citation Mode V2)
# =====================================================
if prompt := st.chat_input("H·ªèi v·ªÅ nghi√™n c·ª©u, b·ªánh l√Ω, b√†i t·∫≠p..."):
    # 1. Hi·ªÉn th·ªã tin nh·∫Øn user
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})
    increment_usage(user_id)

    with st.chat_message("assistant"):
        with st.spinner("üîç ƒêang ƒë·ªëi chi·∫øu c√°c nghi√™n c·ª©u RCT & Meta-Analysis..."):
            try:
                # B∆Ø·ªöC 1: T√¨m ki·∫øm c√≥ ch·∫•m ƒëi·ªÉm (Score)
                # k=10 l√† ƒë·ªß, l·∫•y nhi·ªÅu qu√° s·∫Ω b·ªã lo√£ng
                docs_and_scores = db.similarity_search_with_score(prompt, k=10)
                
                # B∆Ø·ªöC 2: L·ªçc nhi·ªÖu (Quan tr·ªçng!)
                # Score c√†ng th·∫•p c√†ng gi·ªëng. Th∆∞·ªùng < 1.0 l√† ·ªïn, < 0.8 l√† r·∫•t t·ªët.
                # Ta ch·ªâ l·∫•y nh·ªØng t√†i li·ªáu c√≥ li√™n quan th·ª±c s·ª±.
                qualified_docs = []
                for doc, score in docs_and_scores:
                    if score < 1.2: # Ng∆∞·ª°ng l·ªçc (t√πy ch·ªânh n·∫øu c·∫ßn ch·∫∑t h∆°n th√¨ gi·∫£m xu·ªëng 1.0)
                        qualified_docs.append(doc)
                
                if not qualified_docs:
                    st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y nghi√™n c·ª©u n√†o trong d·ªØ li·ªáu kh·ªõp v·ªõi c√¢u h·ªèi n√†y.")
                    st.stop()

                # B∆Ø·ªöC 3: X√¢y d·ª±ng Context c√≥ ƒë√°nh s·ªë ID
                context_text = ""
                source_map = {} # Map t·ª´ ID -> Th√¥ng tin Link
                
                for i, d in enumerate(qualified_docs):
                    doc_id = i + 1
                    url = d.metadata.get('url', '#')
                    title = d.metadata.get('title', 'T√†i li·ªáu kh√¥ng t√™n')
                    type_ = d.metadata.get('type', 'blog')
                    
                    # L∆∞u mapping
                    source_map[doc_id] = {
                        "url": url,
                        "title": title,
                        "type": type_
                    }
                    
                    # Nh·ªìi v√†o context cho AI ƒë·ªçc
                    context_text += f"""
                    --- T√ÄI LI·ªÜU S·ªê [{doc_id}] ---
                    Ti√™u ƒë·ªÅ: {title}
                    N·ªôi dung: {d.page_content}
                    ---------------------------
                    """

                # B∆Ø·ªöC 4: Prompt "Kh√≥a m√µm" (Strict Prompt)
                sys_prompt = f"""
                B·∫°n l√† Tr·ª£ l√Ω Nghi√™n c·ª©u Khoa h·ªçc Yoga (Evidence-Based Yoga).
                Nhi·ªám v·ª•: Tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n c√°c "T√ÄI LI·ªÜU S·ªê" ƒë∆∞·ª£c cung c·∫•p b√™n d∆∞·ªõi.
                
                QUY T·∫ÆC B·∫ÆT BU·ªòC:
                1. M·ªçi th√¥ng tin ƒë∆∞a ra ph·∫£i l·∫•y t·ª´ t√†i li·ªáu. KH√îNG ƒê∆Ø·ª¢C B·ªäA.
                2. Cu·ªëi m·ªói √Ω ho·∫∑c ƒëo·∫°n vƒÉn, PH·∫¢I ghi ch√∫ ngu·ªìn g·ªëc b·∫±ng c√°ch vi·∫øt: [Ngu·ªìn: X] (v·ªõi X l√† s·ªë th·ª© t·ª± t√†i li·ªáu).
                   V√≠ d·ª•: "Yoga gi√∫p gi·∫£m huy·∫øt √°p t√¢m thu [Ngu·ªìn: 1], v√† c·∫£i thi·ªán gi·∫•c ng·ªß [Ngu·ªìn: 2]."
                3. N·∫øu c√¢u h·ªèi kh√¥ng c√≥ trong t√†i li·ªáu, h√£y tr·∫£ l·ªùi: "D·ªØ li·ªáu hi·ªán t·∫°i ch∆∞a c√≥ nghi√™n c·ª©u v·ªÅ v·∫•n ƒë·ªÅ n√†y."
                4. Phong c√°ch: Khoa h·ªçc, kh√°ch quan, tr√≠ch d·∫´n c·ª• th·ªÉ.
                5. ƒê·ªô d√†i t·ªëi ƒëa kh√¥ng qu√° 200 t·ª´.

                D·ªÆ LI·ªÜU ƒê·∫¶U V√ÄO:
                {context_text}
                
                C√ÇU H·ªéI C·ª¶A NG∆Ø·ªúI D√ôNG: "{prompt}"
                """
                
                # G·ªçi Gemini
                response = model.generate_content(sys_prompt)
                ai_raw_text = response.text

                # B∆Ø·ªöC 5: H·∫≠u x·ª≠ l√Ω - Ch·ªâ hi·ªán Link m√† AI th·ª±c s·ª± d√πng
                # Logic: Qu√©t xem AI ƒë√£ vi·∫øt "[Ngu·ªìn: 1]", "[Ngu·ªìn: 2]" n√†o th√¨ hi·ªán link ƒë√≥.
                used_sources = set()
                
                # Thay th·∫ø [Ngu·ªìn: X] th√†nh icon nh·ªè ƒë·∫πp h∆°n trong vƒÉn b·∫£n
                final_text = ai_raw_text
                import re
                
                # T√¨m t·∫•t c·∫£ c√°c s·ªë X trong chu·ªói "[Ngu·ªìn: X]"
                matches = re.findall(r'\[Ngu·ªìn: (\d+)\]', ai_raw_text)
                for m in matches:
                    doc_id = int(m)
                    if doc_id in source_map:
                        used_sources.add(doc_id)
                        # T·∫°o hi·ªáu ·ª©ng highlight nh·ªè trong vƒÉn b·∫£n (t√πy ch·ªçn)
                        # final_text = final_text.replace(f"[Ngu·ªìn: {doc_id}]", f" **(Ref.{doc_id})**")

                # Hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi
                st.markdown(final_text)
                
                # Hi·ªÉn th·ªã Link (Ch·ªâ nh·ªØng link c√≥ trong used_sources)
                if used_sources:
                    st.markdown("---")
                    st.markdown("#### üìö T√†i li·ªáu tham kh·∫£o & Ki·ªÉm ch·ª©ng:")
                    
                    # S·∫Øp x·∫øp ƒë·ªÉ hi·ªán theo th·ª© t·ª± 1, 2, 3...
                    sorted_ids = sorted(list(used_sources))
                    
                    for doc_id in sorted_ids:
                        info = source_map[doc_id]
                        if len(str(info['url'])) > 5: # Ch·ªâ hi·ªán n·∫øu c√≥ link th·∫≠t
                            tag_label = "NGHI√äN C·ª®U RCT" if info['type'] == 'science' else "B√ÄI VI·∫æT CHUY√äN GIA"
                            tag_color = "#e3f2fd" if info['type'] == 'science' else "#e8f5e9"
                            text_color = "#1565c0" if info['type'] == 'science' else "#2e7d32"
                            
                            st.markdown(f"""
                            <div style="margin-bottom:8px; background: {tag_color}; padding: 8px; border-radius: 8px; border-left: 4px solid {text_color};">
                                <span style="font-weight:bold; font-size:0.8em; color:{text_color}; margin-right:5px;">[{doc_id}] {tag_label}</span>
                                <a href="{info['url']}" target="_blank" style="text-decoration:none; color:#333; font-weight:500;">
                                    {info['title']}
                                </a>
                            </div>
                            """, unsafe_allow_html=True)
                else:
                    # Tr∆∞·ªùng h·ª£p AI tr·∫£ l·ªùi nh∆∞ng qu√™n tr√≠ch d·∫´n (Hi·∫øm g·∫∑p v·ªõi prompt n√†y)
                    # Ta c√≥ th·ªÉ hi·ªán fallback 3 link ƒë·∫ßu ti√™n c√≥ ƒë·ªô kh·ªõp cao nh·∫•t
                    if len(qualified_docs) > 0:
                        st.markdown("---")
                        st.caption("C√°c ngu·ªìn c√≥ li√™n quan nh·∫•t (AI t·ªïng h·ª£p):")
                        for i in range(min(3, len(qualified_docs))):
                            info = source_map[i+1]
                            st.markdown(f"- [{info['title']}]({info['url']})")

                # L∆∞u l·ªãch s·ª≠
                st.session_state.messages.append({"role": "assistant", "content": final_text})

            except Exception as e:
                st.error(f"L·ªói x·ª≠ l√Ω: {str(e)}")
