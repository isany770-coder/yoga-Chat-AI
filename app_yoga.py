import streamlit as st
import os
import re
import json
import datetime
import google.generativeai as genai
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import FAISS

# --- C·∫§U H√åNH TRANG ---
st.set_page_config(
    page_title="Yoga Assistant", 
    page_icon="üßò", 
    layout="wide", 
    initial_sidebar_state="collapsed",
    menu_items=None
)

# --- CSS ·∫®N THANH C√îNG C·ª§ & FOOTER ---
st.markdown("""
<style>

/* ===== RESET TO√ÄN B·ªò N·ªÄN ===== */
html, body {
    background: #ffffff !important;
}

[data-testid="stAppViewContainer"],
[data-testid="stApp"],
.stApp {
    background-color: #ffffff !important;
    opacity: 1 !important;
}

/* ===== ·∫®N TOOLBAR AN TO√ÄN (KH√îNG PH√Å LAYOUT) ===== */
[data-testid="stToolbar"] {
    visibility: hidden;
    height: 0;
}

/* KH√îNG hide header/footer b·∫±ng display:none */
header, footer {
    visibility: hidden;
    height: 0;
}

/* ===== FIX MOBILE TEXT M·ªú ===== */
* {
    -webkit-font-smoothing: antialiased !important;
    -moz-osx-font-smoothing: grayscale !important;
}

iframe {
    background: #ffffff !important;
}

/* ===== CHAT UI ===== */
div[data-testid="stChatMessage"] {
    background-color: #f8f9fa;
    border-radius: 14px;
    padding: 12px;
    margin-top: 24px;
    border: 1px solid #eee;
}

div[data-testid="stChatMessage"][data-test-role="user"] {
    background-color: #e3f2fd;
    flex-direction: row-reverse;
    text-align: right;
    border: none;
}

/* ===== LINK ===== */
.stMarkdown a {
    color: #6c5ce7 !important;
    font-weight: 600;
    text-decoration: none;
}
.stMarkdown a:hover {
    text-decoration: underline;
}

/* ===== MOBILE FIX ===== */
@media (max-width: 600px) {
    body {
        overflow: auto !important;
    }
}

</style>
""", unsafe_allow_html=True)


# --- KH·ªûI T·∫†O API ---
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
except: st.stop()

CURRENT_DIR = os.getcwd()
VECTOR_DB_PATH = os.path.join(CURRENT_DIR, "bo_nao_vector")
USAGE_DB_FILE = "usage_database.json"
DAILY_LIMIT = 25
TRIAL_LIMIT = 10

def load_usage_db():
    if not os.path.exists(USAGE_DB_FILE): return {}
    with open(USAGE_DB_FILE, "r") as f: return json.load(f)
def save_usage_db(data):
    with open(USAGE_DB_FILE, "w") as f: json.dump(data, f)
def check_member_limit(username):
    data = load_usage_db()
    today = str(datetime.date.today())
    if username not in data or data[username]["date"] != today:
        data[username] = {"date": today, "count": 0}
        save_usage_db(data)
        return 0, DAILY_LIMIT
    return data[username]["count"], DAILY_LIMIT - data[username]["count"]
def increment_member_usage(username):
    data = load_usage_db()
    today = str(datetime.date.today())
    if username in data and data[username]["date"] == today:
        data[username]["count"] += 1
        save_usage_db(data)

SPECIAL_MAPPING = {"tr·ªìng chu·ªëi": ["sirsasana"], "con qu·∫°": ["bakasana"], "c√°i c√†y": ["halasana"]}
STOPWORDS = {'l√†', 'c·ªßa', 'nh∆∞', 'th·∫ø', 'n√†o', 't·∫≠p', 'b√†i', 'c√°ch', 't√¥i', 'b·∫°n', 'mu·ªën', 'h·ªèi', 'g√¨'}
def clean_and_extract_keywords(text):
    text = text.lower()
    text = re.sub(r'[^\w\s]', ' ', text)
    return set([w for w in text.split() if w not in STOPWORDS and len(w) > 1])

@st.cache_resource
def load_brain():
    if not os.path.exists(VECTOR_DB_PATH): return None, None
    embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004", google_api_key=api_key)
    try:
        db = FAISS.load_local(VECTOR_DB_PATH, embeddings, allow_dangerous_deserialization=True)
        model = genai.GenerativeModel('gemini-flash-latest') 
        return db, model
    except: return None, None

db, model = load_brain()

def search_engine(query, db):
    user_keywords = clean_and_extract_keywords(query)
    injected_keywords = set()
    for key, values in SPECIAL_MAPPING.items():
        if key in query.lower(): injected_keywords.update(values)
    if not user_keywords: user_keywords = set(query.lower().split())
    
    raw_docs = db.similarity_search(f"{query} {' '.join(injected_keywords)}", k=100)
    matched_docs = []
    seen = set()
    for d in raw_docs:
        title = d.metadata.get('title', 'T√†i li·ªáu Yoga')
        if title in seen: continue
        score = 0
        title_keywords = clean_and_extract_keywords(title)
        common = user_keywords.intersection(title_keywords)
        if common: score += len(common) * 10
        if score > 0: 
            matched_docs.append((d, score))
            seen.add(title)
    matched_docs.sort(key=lambda x: x[1], reverse=True)
    return [x[0] for x in matched_docs[:3]]

# --- LOGIC CHAT ---
if "authenticated" not in st.session_state: st.session_state.authenticated = False
if "username" not in st.session_state: st.session_state.username = ""
if "guest_usage" not in st.session_state: st.session_state.guest_usage = 0
if "messages" not in st.session_state: st.session_state.messages = [{"role": "assistant", "content": "Namaste! üôè Ch√∫c b·∫°n m·ªôt ng√†y nhi·ªÅu ni·ªÅm vui, ch√∫ng ta s·∫Ω b·∫Øt ƒë·∫ßu t·ª´ ƒë√¢u?."}]

can_chat = False
if st.session_state.authenticated:
    used, remaining = check_member_limit(st.session_state.username)
    if remaining > 0: can_chat = True
    else: st.warning("‚õî H√¥m nay b·∫°n ƒë√£ h·ªèi ƒë·ªß 25 c√¢u.")
else:
    if st.session_state.guest_usage < TRIAL_LIMIT: can_chat = True
    else: st.info(f"üîí D√πng th·ª≠: {st.session_state.guest_usage}/{TRIAL_LIMIT} c√¢u.")

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]): st.markdown(msg["content"], unsafe_allow_html=True)

if can_chat:
    if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"): st.markdown(prompt)
        
        with st.chat_message("assistant"):
            if db:
                top_docs = search_engine(prompt, db)
                if st.session_state.authenticated: increment_member_usage(st.session_state.username)
                else: st.session_state.guest_usage += 1
                
                # --- PH·∫¶N KH√îI PH·ª§C LOGIC LINK ƒê·∫∏P ---
                links_markdown = ""
                context = ""
                final_links = {} # D√πng dict ƒë·ªÉ l·ªçc tr√πng l·∫∑p link
                
                if top_docs:
                    context = "\n".join([d.page_content for d in top_docs])
                    
                    for d in top_docs:
                        title = d.metadata.get('title', 'T√†i li·ªáu tham kh·∫£o')
                        url = d.metadata.get('url', '#')
                        # L√†m s·∫°ch ti√™u ƒë·ªÅ (b·ªè d·∫•u ngo·∫∑c th·ª´a n·∫øu c√≥)
                        clean_title = title.replace("[", "").replace("]", "").replace("(", " - ").replace(")", "")
                        
                        if url != '#' and "http" in url:
                            final_links[url] = clean_title

                    # T·∫°o Markdown list
                    if final_links:
                        links_markdown = "\n\n---\n**üìö T√†i li·ªáu tham kh·∫£o:**\n"
                        for url, name in final_links.items():
                            links_markdown += f"- üîó [{name}]({url})\n"
                
                sys_prompt = f"""
                B·∫°n l√† chuy√™n gia Yoga.
                D·ªÆ LI·ªÜU B√ÄI VI·∫æT:
                {context}
                C√ÇU H·ªéI: "{prompt}"
                Y√äU C·∫¶U:
                1. Tr·∫£ l·ªùi C·ª∞C K·ª≤ NG·∫ÆN G·ªåN (T·ªëi ƒëa 5-6 g·∫°ch ƒë·∫ßu d√≤ng).
                2. T·ªïng ƒë·ªô d√†i KH√îNG QU√Å 100 T·ª™.
                3. ƒêi th·∫≥ng v√†o tr·ªçng t√¢m, b·ªè qua l·ªùi d·∫´n d·∫Øt v√¥ nghƒ©a.
                4. Gi·ªçng vƒÉn th√¢n thi·ªán, d·ª©t kho√°t.
                5. KH√îNG t·ª± ch√®n link (H·ªá th·ªëng s·∫Ω t·ª± l√†m).
                """
                
                try:
                    response_text = model.generate_content(sys_prompt).text
                    final_content = response_text + links_markdown
                    st.markdown(final_content, unsafe_allow_html=True)
                    st.session_state.messages.append({"role": "assistant", "content": final_content})
                except Exception as e:
                    st.error(f"L·ªói AI: {e}")
            else: st.error("ƒêang k·∫øt n·ªëi n√£o b·ªô...")
else:
    if not st.session_state.authenticated:
        st.markdown("---")
        with st.form("login"):
            st.markdown("### üîê ƒêƒÉng nh·∫≠p Th√†nh vi√™n")
            u = st.text_input("User")
            p = st.text_input("Pass", type="password")
            if st.form_submit_button("V√†o t·∫≠p"):
                if st.secrets["passwords"].get(u) == p:
                    st.session_state.authenticated = True; st.session_state.username = u; st.rerun()
                else: st.error("Sai th√¥ng tin!")
        st.markdown(f"<div style='text-align:center; margin-top:10px'><a href='https://zalo.me/84963759566' target='_blank' style='color:#6c5ce7; text-decoration:none; font-weight:bold'>üí¨ L·∫•y TK Zalo</a></div>", unsafe_allow_html=True)
