import streamlit as st
import os
import re
import json
import datetime
import google.generativeai as genai
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import FAISS

# --- C·∫§U H√åNH TRANG ---
st.set_page_config(page_title="Yoga Guru AI", page_icon="üßò", layout="wide")

# --- CSS T√ôY CH·ªàNH (GIAO DI·ªÜN ƒê·∫∏P) ---
st.markdown("""
<style>
    .stChatMessage {font-size: 16px; line-height: 1.6;} 
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    .stMarkdown a {color: #007bff !important; font-weight: bold !important; text-decoration: none;}
    .stMarkdown a:hover {text-decoration: underline;}
    div[data-testid="stForm"] {border: 1px solid #ddd; padding: 20px; border-radius: 10px;}
</style>
""", unsafe_allow_html=True)

# --- C·∫§U H√åNH API ---
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
except:
    st.error("‚ö†Ô∏è L·ªói: Ch∆∞a c·∫•u h√¨nh API Key.")
    st.stop()

VECTOR_DB_PATH = "bo_nao_vector"
USAGE_DB_FILE = "usage_database.json"
DAILY_LIMIT = 15   # Gi·ªõi h·∫°n cho th√†nh vi√™n (15 c√¢u/ng√†y)
TRIAL_LIMIT = 5    # Gi·ªõi h·∫°n d√πng th·ª≠ cho kh√°ch (5 c√¢u)

# --- QU·∫¢N L√ù QUOTA ---
def load_usage_db():
    if not os.path.exists(USAGE_DB_FILE): return {}
    with open(USAGE_DB_FILE, "r") as f: return json.load(f)

def save_usage_db(data):
    with open(USAGE_DB_FILE, "w") as f: json.dump(data, f)

def check_member_limit(username):
    data = load_usage_db()
    today = str(datetime.date.today())
    if username not in data or data[username]["date"] != today:
        data[username] = {"date": today, "count": 0}
        save_usage_db(data)
        return 0, DAILY_LIMIT
    used = data[username]["count"]
    return used, DAILY_LIMIT - used

def increment_member_usage(username):
    data = load_usage_db()
    today = str(datetime.date.today())
    if username in data and data[username]["date"] == today:
        data[username]["count"] += 1
        save_usage_db(data)

# --- X·ª¨ L√ù T√åM KI·∫æM ---
SPECIAL_MAPPING = {
    "tr·ªìng chu·ªëi": ["sirsasana", "headstand", "ƒë·ª©ng b·∫±ng ƒë·∫ßu"],
    "con qu·∫°": ["bakasana", "crow"],
    "c√°i c√†y": ["halasana", "plow"],
    "tam gi√°c": ["trikonasana", "triangle"],
    "x√°c ch·∫øt": ["savasana", "corpse"],
    "b√°nh xe": ["chakrasana", "wheel"],
    "ch√≥ √∫p m·∫∑t": ["adho mukha svanasana", "downward facing dog"],
    "r·∫Øn h·ªï mang": ["bhujangasana", "cobra"]
}

STOPWORDS = {'l√†', 'c·ªßa', 'nh·ªØng', 'c√°i', 'vi·ªác', 'trong', 'khi', 'b·ªã', 'v·ªõi', 'cho', 'ƒë∆∞·ª£c', 't·∫°i', 'v√¨', 'sao', 'th√¨', 'l·∫°i', 'm√†', 'v√†', 'c√°c', 'c√≥', 'nh∆∞', 'ƒë·ªÉ', 'n√†y', 'ƒë√≥', 'v·ªÅ', 'theo', 'nh·∫•t', 'g√¨', 'th·∫ø', 'n√†o', 'l√†m', 't·∫≠p', 'b√†i', 'c√°ch', 'nh∆∞', 'th·∫ø', 'n√†o', 't√¥i', 'b·∫°n', 'mu·ªën', 'h·ªèi'}

def clean_and_extract_keywords(text):
    text = text.lower()
    text = re.sub(r'[^\w\s]', ' ', text)
    words = text.split()
    return set([w for w in words if w not in STOPWORDS and len(w) > 1])

@st.cache_resource
def load_brain():
    if not os.path.exists(VECTOR_DB_PATH): return None, None
    embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004", google_api_key=api_key)
    try:
        db = FAISS.load_local(VECTOR_DB_PATH, embeddings, allow_dangerous_deserialization=True)
        model = genai.GenerativeModel('gemini-1.5-flash-latest') 
        return db, model
    except: return None, None

db, model = load_brain()

def search_engine(query, db):
    query_lower = query.lower()
    user_keywords = clean_and_extract_keywords(query)
    injected_keywords = set()
    for key, values in SPECIAL_MAPPING.items():
        if key in query_lower:
            injected_keywords.update(values)
            user_keywords.update(values)
    if not user_keywords: user_keywords = set(query_lower.split())
    vector_query = f"{query} {' '.join(injected_keywords)}"
    raw_docs = db.similarity_search(vector_query, k=200)
    matched_docs = []
    for d in raw_docs:
        title = d.metadata.get('title', 'No Title')
        content = d.page_content
        title_keywords = clean_and_extract_keywords(title)
        score = 0
        common_words = user_keywords.intersection(title_keywords)
        if len(common_words) > 0:
            score += len(common_words) * 10
            for inj in injected_keywords:
                if inj in title.lower(): score += 500
            match_ratio = len(common_words) / len(user_keywords) if len(user_keywords) > 0 else 0
            if match_ratio >= 0.5: score += 50
        if score == 0:
            content_keywords = clean_and_extract_keywords(content[:500])
            common_content = user_keywords.intersection(content_keywords)
            if len(common_content) > 0: score += len(common_content)
        if score > 0: matched_docs.append((d, score))
    matched_docs.sort(key=lambda x: x[1], reverse=True)
    return [x[0] for x in matched_docs[:6]]

# --- TR·∫†NG TH√ÅI PHI√äN ---
if "authenticated" not in st.session_state: st.session_state.authenticated = False
if "username" not in st.session_state: st.session_state.username = ""
if "guest_usage" not in st.session_state: st.session_state.guest_usage = 0
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "Namaste! üôè H·ªèi m√¨nh b·∫•t c·ª© ƒëi·ªÅu g√¨ v·ªÅ Yoga nh√©."}]

# --- SIDEBAR ---
with st.sidebar:
    st.title("üßò Yoga Guru AI")
    
    if st.session_state.authenticated:
        st.success(f"üë§ {st.session_state.username}")
        used, remaining = check_member_limit(st.session_state.username)
        st.progress(used / DAILY_LIMIT)
        st.caption(f"ƒê√£ d√πng: {used}/{DAILY_LIMIT} c√¢u")
        if st.button("üö™ ƒêƒÉng xu·∫•t"):
            st.session_state.authenticated = False
            st.rerun()
    else:
        st.info(f"‚ö° D√πng th·ª≠: **{st.session_state.guest_usage}/{TRIAL_LIMIT}** c√¢u")
        if st.session_state.guest_usage >= TRIAL_LIMIT:
            st.warning("üîí H·∫øt l∆∞·ª£t th·ª≠. Vui l√≤ng ƒëƒÉng nh·∫≠p.")
            with st.form("login_form"):
                user_input = st.text_input("T√†i kho·∫£n")
                pass_input = st.text_input("M·∫≠t kh·∫©u", type="password")
                if st.form_submit_button("ƒêƒÉng nh·∫≠p"):
                    secrets_pass = st.secrets["passwords"].get(user_input)
                    if secrets_pass and secrets_pass == pass_input:
                        st.session_state.authenticated = True
                        st.session_state.username = user_input
                        st.rerun()
                    else: st.error("Sai th√¥ng tin!")
        else:
             st.caption("üí° ƒêƒÉng nh·∫≠p ƒë·ªÉ s·ª≠ d·ª•ng 15 c√¢u/ng√†y.")
             with st.expander("üîê ƒêƒÉng nh·∫≠p th√†nh vi√™n"):
                with st.form("login_form_guest"):
                    user_input = st.text_input("T√†i kho·∫£n")
                    pass_input = st.text_input("M·∫≠t kh·∫©u", type="password")
                    if st.form_submit_button("V√†o"):
                        secrets_pass = st.secrets["passwords"].get(user_input)
                        if secrets_pass and secrets_pass == pass_input:
                            st.session_state.authenticated = True
                            st.session_state.username = user_input
                            st.rerun()
                        else: st.error("Sai th√¥ng tin!")

# --- GIAO DI·ªÜN CHAT ---
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# --- KI·ªÇM TRA QUY·ªÄN CHAT ---
can_chat = False
if st.session_state.authenticated:
    used, remaining = check_member_limit(st.session_state.username)
    if remaining > 0: can_chat = True
else:
    if st.session_state.guest_usage < TRIAL_LIMIT: can_chat = True

if can_chat:
    if prompt := st.chat_input("VD: ƒêau l∆∞ng t·∫≠p g√¨? K·ªπ thu·∫≠t con qu·∫°..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"): st.markdown(prompt)

        with st.chat_message("assistant"):
            if db is None:
                st.error("L·ªói k·∫øt n·ªëi DB."); st.stop()
            
            msg_placeholder = st.empty()
            msg_placeholder.markdown("üßò *ƒêang t√¨m...*")
            
            try:
                top_docs = search_engine(prompt, db)
                
                if st.session_state.authenticated: increment_member_usage(st.session_state.username)
                else: st.session_state.guest_usage += 1

                if not top_docs:
                    resp = "Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p trong d·ªØ li·ªáu."
                    msg_placeholder.markdown(resp)
                    st.session_state.messages.append({"role": "assistant", "content": resp})
                else:
                    context = ""
                    links = {}
                    for i, d in enumerate(top_docs):
                        title = d.metadata.get('title', 'No Title')
                        url = d.metadata.get('url', '#')
                        context += f"[B√ÄI {i+1}]: {title}\nN·ªôi dung: {d.page_content}\n\n"
                        if url != '#' and "http" in url and url not in links:
                             clean = title.replace("[", "").replace("]", "").replace("(", " - ").replace(")", "")
                             links[url] = clean
                    
                    link_md = ""
                    if links:
                        link_md = "\n\n---\n**üìö Tham kh·∫£o:**\n" + "\n".join([f"- [{n}]({u})" for u, n in links.items()])

                    # --- PROMPT V32: 10 √ù - 200 T·ª™ ---
                    sys_prompt = f"""
                    B·∫°n l√† chuy√™n gia Yoga.
                    D·ª±a tr√™n d·ªØ li·ªáu d∆∞·ªõi ƒë√¢y, tr·∫£ l·ªùi c√¢u h·ªèi.
                    
                    D·ªÆ LI·ªÜU:
                    {context}
                    
                    C√ÇU H·ªéI: "{prompt}"
                    
                    Y√äU C·∫¶U TR√åNH B√ÄY:
                    1. Tr·∫£ l·ªùi chi ti·∫øt, li·ªát k√™ kho·∫£ng **8-10 g·∫°ch ƒë·∫ßu d√≤ng** c√°c √Ω quan tr·ªçng nh·∫•t.
                    2. T·ªïng ƒë·ªô d√†i kho·∫£ng **200 t·ª´** (kh√¥ng qu√° d√†i, kh√¥ng qu√° ng·∫Øn).
                    3. B·ªè qua l·ªùi ch√†o h·ªèi s√°o r·ªóng, ƒëi th·∫≥ng v√†o ki·∫øn th·ª©c.
                    4. Tr√¨nh b√†y tho√°ng, ƒë·∫πp.
                    5. KH√îNG t·ª± vi·∫øt link.
                    """
                    
                    response = model.generate_content(sys_prompt)
                    full_resp = response.text + link_md
                    msg_placeholder.markdown(full_resp)
                    st.session_state.messages.append({"role": "assistant", "content": full_resp})
                    st.rerun()

            except Exception as e: st.error("L·ªói x·ª≠ l√Ω."); print(e)
else:
    if st.session_state.authenticated:
        st.info("‚õî H√¥m nay b·∫°n ƒë√£ h·ªèi ƒë·ªß 15 c√¢u r·ªìi. H·∫πn g·∫∑p l·∫°i ng√†y mai nh√©!")
    else:
        st.warning(f"üîí B·∫°n ƒë√£ h·∫øt {TRIAL_LIMIT} c√¢u h·ªèi mi·ªÖn ph√≠. Vui l√≤ng **ƒêƒÉng nh·∫≠p** ·ªü c·ªôt b√™n tr√°i ƒë·ªÉ ti·∫øp t·ª•c.")
