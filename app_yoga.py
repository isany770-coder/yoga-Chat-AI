import streamlit as st
import os
import re
import json
import datetime
import google.generativeai as genai
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import FAISS

# --- Cáº¤U HÃŒNH TRANG ---
st.set_page_config(page_title="Yoga Guru AI", page_icon="ğŸ§˜", layout="wide")

# --- CSS TÃ™Y CHá»ˆNH ---
st.markdown("""
<style>
    .stChatMessage {font-size: 16px; line-height: 1.6;} 
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    .stMarkdown a {color: #007bff !important; font-weight: bold !important; text-decoration: none;}
    .stMarkdown a:hover {text-decoration: underline;}
    /* Style cho khung Ä‘Äƒng nháº­p */
    div[data-testid="stForm"] {border: 1px solid #ddd; padding: 20px; border-radius: 10px;}
</style>
""", unsafe_allow_html=True)

# --- Cáº¤U HÃŒNH API & DATABASE ---
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
except:
    st.error("âš ï¸ Lá»—i: ChÆ°a cáº¥u hÃ¬nh API Key trong .streamlit/secrets.toml")
    st.stop()

VECTOR_DB_PATH = "bo_nao_vector"
USAGE_DB_FILE = "usage_database.json"
DAILY_LIMIT = 10  # Giá»›i háº¡n 15 cÃ¢u/ngÃ y

# --- QUáº¢N LÃ QUOTA NGÆ¯á»œI DÃ™NG (LÆ¯U FILE JSON) ---
def load_usage_db():
    if not os.path.exists(USAGE_DB_FILE):
        return {}
    with open(USAGE_DB_FILE, "r") as f:
        return json.load(f)

def save_usage_db(data):
    with open(USAGE_DB_FILE, "w") as f:
        json.dump(data, f)

def check_user_limit(username):
    data = load_usage_db()
    today = str(datetime.date.today())
    
    # Náº¿u user chÆ°a cÃ³ trong DB hoáº·c qua ngÃ y má»›i -> Reset
    if username not in data or data[username]["date"] != today:
        data[username] = {"date": today, "count": 0}
        save_usage_db(data)
        return 0, DAILY_LIMIT # ÄÃ£ dÃ¹ng 0, CÃ²n láº¡i 10
    
    used = data[username]["count"]
    return used, DAILY_LIMIT - used

def increment_user_usage(username):
    data = load_usage_db()
    today = str(datetime.date.today())
    
    if username in data and data[username]["date"] == today:
        data[username]["count"] += 1
        save_usage_db(data)

# --- Tá»ª KHÃ“A & LOGIC TÃŒM KIáº¾M (GIá»® NGUYÃŠN V30) ---
SPECIAL_MAPPING = {
    "trá»“ng chuá»‘i": ["sirsasana", "headstand", "Ä‘á»©ng báº±ng Ä‘áº§u"],
    "con quáº¡": ["bakasana", "crow"],
    "cÃ¡i cÃ y": ["halasana", "plow"],
    "tam giÃ¡c": ["trikonasana", "triangle"],
    "xÃ¡c cháº¿t": ["savasana", "corpse"],
    "bÃ¡nh xe": ["chakrasana", "wheel"],
    "chÃ³ Ãºp máº·t": ["adho mukha svanasana", "downward facing dog"],
    "ráº¯n há»• mang": ["bhujangasana", "cobra"]
}

STOPWORDS = {
    'lÃ ', 'cá»§a', 'nhá»¯ng', 'cÃ¡i', 'viá»‡c', 'trong', 'khi', 'bá»‹', 'vá»›i', 'cho', 'Ä‘Æ°á»£c', 
    'táº¡i', 'vÃ¬', 'sao', 'thÃ¬', 'láº¡i', 'mÃ ', 'vÃ ', 'cÃ¡c', 'cÃ³', 'nhÆ°', 'Ä‘á»ƒ', 'nÃ y', 
    'Ä‘Ã³', 'vá»', 'theo', 'nháº¥t', 'gÃ¬', 'tháº¿', 'nÃ o', 'lÃ m', 'táº­p', 'bÃ i', 'cÃ¡ch',
    'nhÆ°', 'tháº¿', 'nÃ o', 'tÃ´i', 'báº¡n', 'muá»‘n', 'há»i'
}

def clean_and_extract_keywords(text):
    text = text.lower()
    text = re.sub(r'[^\w\s]', ' ', text)
    words = text.split()
    return set([w for w in words if w not in STOPWORDS and len(w) > 1])

@st.cache_resource
def load_brain():
    if not os.path.exists(VECTOR_DB_PATH): return None, None
    embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004", google_api_key=api_key)
    try:
        db = FAISS.load_local(VECTOR_DB_PATH, embeddings, allow_dangerous_deserialization=True)
        model = genai.GenerativeModel('gemini-flash-latest') 
        return db, model
    except Exception as e:
        return None, None

db, model = load_brain()

def search_engine(query, db):
    query_lower = query.lower()
    user_keywords = clean_and_extract_keywords(query)
    
    injected_keywords = set()
    for key, values in SPECIAL_MAPPING.items():
        if key in query_lower:
            injected_keywords.update(values)
            user_keywords.update(values)
    
    if not user_keywords:
        user_keywords = set(query_lower.split())

    vector_query = f"{query} {' '.join(injected_keywords)}"
    raw_docs = db.similarity_search(vector_query, k=200)
    
    matched_docs = []
    for d in raw_docs:
        title = d.metadata.get('title', 'No Title')
        content = d.page_content
        title_keywords = clean_and_extract_keywords(title)
        score = 0
        
        common_words = user_keywords.intersection(title_keywords)
        if len(common_words) > 0:
            score += len(common_words) * 10
            for inj in injected_keywords:
                if inj in title.lower(): score += 500
            match_ratio = len(common_words) / len(user_keywords) if len(user_keywords) > 0 else 0
            if match_ratio >= 0.5: score += 50

        if score == 0:
            content_keywords = clean_and_extract_keywords(content[:500])
            common_content = user_keywords.intersection(content_keywords)
            if len(common_content) > 0: score += len(common_content)

        if score > 0: matched_docs.append((d, score))
            
    matched_docs.sort(key=lambda x: x[1], reverse=True)
    return [x[0] for x in matched_docs[:6]]

# --- LOGIC ÄÄ‚NG NHáº¬P (SIDEBAR) ---
if "authenticated" not in st.session_state:
    st.session_state.authenticated = False
if "username" not in st.session_state:
    st.session_state.username = ""

with st.sidebar:
    st.title("ğŸ§˜ Yoga Guru AI")
    
    if not st.session_state.authenticated:
        st.subheader("ğŸ” ÄÄƒng nháº­p")
        with st.form("login_form"):
            user_input = st.text_input("TÃ i khoáº£n")
            pass_input = st.text_input("Máº­t kháº©u", type="password")
            submit_btn = st.form_submit_button("VÃ o táº­p")
            
            if submit_btn:
                # Kiá»ƒm tra trong secrets
                secrets_pass = st.secrets["passwords"].get(user_input)
                if secrets_pass and secrets_pass == pass_input:
                    st.session_state.authenticated = True
                    st.session_state.username = user_input
                    st.success("ÄÄƒng nháº­p thÃ nh cÃ´ng!")
                    st.rerun()
                else:
                    st.error("Sai tÃ i khoáº£n hoáº·c máº­t kháº©u")
    else:
        # ÄÃ£ Ä‘Äƒng nháº­p
        st.success(f"Xin chÃ o, **{st.session_state.username}**! ğŸ‘‹")
        
        # Kiá»ƒm tra sá»‘ lÆ°á»£t cÃ²n láº¡i
        used, remaining = check_user_limit(st.session_state.username)
        
        # Thanh tiáº¿n trÃ¬nh
        progress = used / DAILY_LIMIT
        st.progress(progress)
        st.write(f"ğŸ’¬ HÃ´m nay: **{used}/{DAILY_LIMIT}** cÃ¢u")
        
        if st.button("ğŸšª ÄÄƒng xuáº¥t"):
            st.session_state.authenticated = False
            st.session_state.username = ""
            st.rerun()
            
    st.markdown("---")
    st.caption("Powered by Yoga Is My Life")

# --- GIAO DIá»†N CHAT CHÃNH ---
if st.session_state.authenticated:
    # Check limit trÆ°á»›c khi cho hiá»‡n khung chat
    used, remaining = check_user_limit(st.session_state.username)
    
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "Namaste! ğŸ™ Trá»£ lÃ½ Yoga (Final Stable) Ä‘Ã£ sáºµn sÃ ng.\nChÃºng ta nÃªn báº¯t Ä‘áº§u tá»« Ä‘Ã¢u nhá»‰?."}
        ]

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    if remaining > 0:
        if prompt := st.chat_input("VD: Táº¡i sao táº­p bá»¥ng Ä‘au lÆ°ng? Ká»¹ thuáº­t trá»“ng chuá»‘i..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            with st.chat_message("assistant"):
                if db is None:
                    st.error("âš ï¸ Lá»—i káº¿t ná»‘i Database.")
                    st.stop()
                    
                message_placeholder = st.empty()
                message_placeholder.markdown("ğŸ§˜ *Äang tra cá»©u...*")

                try:
                    top_docs = search_engine(prompt, db)
                    
                    if not top_docs:
                        response_text = "Xin lá»—i, mÃ¬nh khÃ´ng tÃ¬m tháº¥y tÃ i liá»‡u phÃ¹ há»£p trong thÆ° viá»‡n."
                        message_placeholder.markdown(response_text)
                        st.session_state.messages.append({"role": "assistant", "content": response_text})
                    else:
                        # TÃ¬m tháº¥y bÃ i -> Trá»« lÆ°á»£t ngay láº­p tá»©c
                        increment_user_usage(st.session_state.username)
                        
                        context_text = ""
                        final_links = {}
                        for i, d in enumerate(top_docs):
                            title = d.metadata.get('title', 'No Title')
                            url = d.metadata.get('url', '#')
                            context_text += f"[TÃ€I LIá»†U {i+1}]: {title}\nNá»™i dung: {d.page_content}\n\n"
                            if url != '#' and "http" in url and url not in final_links:
                                 clean_title = title.replace("[", "").replace("]", "").replace("(", " - ").replace(")", "")
                                 final_links[url] = clean_title

                        links_markdown = ""
                        if final_links:
                            links_markdown = "\n\n---\n**ğŸ“š TÃ i liá»‡u tham kháº£o:**\n"
                            for url, name in final_links.items():
                                links_markdown += f"- ğŸ”— [{name}]({url})\n"

                        system_prompt = f"""
                        Báº¡n lÃ  chuyÃªn gia Yoga.
                        Dá»® LIá»†U BÃ€I VIáº¾T:
                        {context_text}
                        CÃ‚U Há»I: "{prompt}"
                        YÃŠU Cáº¦U:
                        1. **Trung thá»±c:** Chá»‰ tráº£ lá»i dá»±a trÃªn thÃ´ng tin cÃ³ trong tÃ i liá»‡u.
            2. **ChuyÃªn mÃ´n:** Náº¿u lÃ  cÃ¢u há»i ká»¹ thuáº­t, hÃ£y hÆ°á»›ng dáº«n tá»«ng bÆ°á»›c rÃµ rÃ ng, chÃº Ã½ Ä‘áº¿n hÆ¡i thá»Ÿ vÃ  Ä‘á»‹nh tuyáº¿n an toÃ n.
            3. **Cáº¥u trÃºc:** Tráº£ lá»i ngáº¯n gá»n, sÃºc tÃ­ch, sá»­ dá»¥ng gáº¡ch Ä‘áº§u dÃ²ng Ä‘á»ƒ dá»… Ä‘á»c.
            4. **LÆ°u Ã½:** KHÃ”NG tá»± Ã½ chÃ¨n Ä‘Æ°á»ng link vÃ o ná»™i dung tráº£ lá»i (Há»‡ thá»‘ng sáº½ tá»± Ä‘á»™ng thÃªm danh sÃ¡ch tham kháº£o á»Ÿ cuá»‘i).
            """
                        
                        response = model.generate_content(system_prompt)
                        full_response = response.text + links_markdown
                        
                        message_placeholder.markdown(full_response)
                        st.session_state.messages.append({"role": "assistant", "content": full_response})
                        
                        # Rerun Ä‘á»ƒ cáº­p nháº­t thanh tiáº¿n trÃ¬nh bÃªn trÃ¡i
                        st.rerun()

                except Exception as e:
                    st.error("CÃ³ lá»—i xáº£y ra.")
                    print(e)
    else:
        st.warning("â›” Báº¡n Ä‘Ã£ háº¿t 10 lÆ°á»£t há»i miá»…n phÃ­ hÃ´m nay. Quay láº¡i vÃ o ngÃ y mai nhÃ©!")

else:
    # MÃ n hÃ¬nh chá» khi chÆ°a Ä‘Äƒng nháº­p
    st.info("ğŸ‘ˆ Vui lÃ²ng Ä‘Äƒng nháº­p á»Ÿ thanh bÃªn trÃ¡i Ä‘á»ƒ sá»­ dá»¥ng Trá»£ lÃ½ Yoga.")
